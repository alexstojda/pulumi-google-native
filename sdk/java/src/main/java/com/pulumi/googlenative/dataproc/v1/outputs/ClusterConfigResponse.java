// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.googlenative.dataproc.v1.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.googlenative.dataproc.v1.outputs.AutoscalingConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.DataprocMetricConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.EncryptionConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.EndpointConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.GceClusterConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.GkeClusterConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.InstanceGroupConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.LifecycleConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.MetastoreConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.NodeInitializationActionResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.SecurityConfigResponse;
import com.pulumi.googlenative.dataproc.v1.outputs.SoftwareConfigResponse;
import java.lang.String;
import java.util.List;
import java.util.Objects;

@CustomType
public final class ClusterConfigResponse {
    /**
     * @return Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
     * 
     */
    private AutoscalingConfigResponse autoscalingConfig;
    /**
     * @return Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
     * 
     */
    private String configBucket;
    /**
     * @return Optional. The config for Dataproc metrics.
     * 
     */
    private DataprocMetricConfigResponse dataprocMetricConfig;
    /**
     * @return Optional. Encryption settings for the cluster.
     * 
     */
    private EncryptionConfigResponse encryptionConfig;
    /**
     * @return Optional. Port/endpoint configuration for this cluster
     * 
     */
    private EndpointConfigResponse endpointConfig;
    /**
     * @return Optional. The shared Compute Engine config settings for all instances in a cluster.
     * 
     */
    private GceClusterConfigResponse gceClusterConfig;
    /**
     * @return Optional. BETA. The Kubernetes Engine config for Dataproc clusters deployed to The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. These config settings are mutually exclusive with Compute Engine-based options, such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
     * 
     */
    private GkeClusterConfigResponse gkeClusterConfig;
    /**
     * @return Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node&#39;s role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if [[ &#34;${ROLE}&#34; == &#39;Master&#39; ]]; then ... master specific actions ... else ... worker specific actions ... fi
     * 
     */
    private List<NodeInitializationActionResponse> initializationActions;
    /**
     * @return Optional. Lifecycle setting for the cluster.
     * 
     */
    private LifecycleConfigResponse lifecycleConfig;
    /**
     * @return Optional. The Compute Engine config settings for the cluster&#39;s master instance.
     * 
     */
    private InstanceGroupConfigResponse masterConfig;
    /**
     * @return Optional. Metastore configuration.
     * 
     */
    private MetastoreConfigResponse metastoreConfig;
    /**
     * @return Optional. The Compute Engine config settings for a cluster&#39;s secondary worker instances
     * 
     */
    private InstanceGroupConfigResponse secondaryWorkerConfig;
    /**
     * @return Optional. Security settings for the cluster.
     * 
     */
    private SecurityConfigResponse securityConfig;
    /**
     * @return Optional. The config settings for cluster software.
     * 
     */
    private SoftwareConfigResponse softwareConfig;
    /**
     * @return Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
     * 
     */
    private String tempBucket;
    /**
     * @return Optional. The Compute Engine config settings for the cluster&#39;s worker instances.
     * 
     */
    private InstanceGroupConfigResponse workerConfig;

    private ClusterConfigResponse() {}
    /**
     * @return Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
     * 
     */
    public AutoscalingConfigResponse autoscalingConfig() {
        return this.autoscalingConfig;
    }
    /**
     * @return Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
     * 
     */
    public String configBucket() {
        return this.configBucket;
    }
    /**
     * @return Optional. The config for Dataproc metrics.
     * 
     */
    public DataprocMetricConfigResponse dataprocMetricConfig() {
        return this.dataprocMetricConfig;
    }
    /**
     * @return Optional. Encryption settings for the cluster.
     * 
     */
    public EncryptionConfigResponse encryptionConfig() {
        return this.encryptionConfig;
    }
    /**
     * @return Optional. Port/endpoint configuration for this cluster
     * 
     */
    public EndpointConfigResponse endpointConfig() {
        return this.endpointConfig;
    }
    /**
     * @return Optional. The shared Compute Engine config settings for all instances in a cluster.
     * 
     */
    public GceClusterConfigResponse gceClusterConfig() {
        return this.gceClusterConfig;
    }
    /**
     * @return Optional. BETA. The Kubernetes Engine config for Dataproc clusters deployed to The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. These config settings are mutually exclusive with Compute Engine-based options, such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
     * 
     */
    public GkeClusterConfigResponse gkeClusterConfig() {
        return this.gkeClusterConfig;
    }
    /**
     * @return Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node&#39;s role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if [[ &#34;${ROLE}&#34; == &#39;Master&#39; ]]; then ... master specific actions ... else ... worker specific actions ... fi
     * 
     */
    public List<NodeInitializationActionResponse> initializationActions() {
        return this.initializationActions;
    }
    /**
     * @return Optional. Lifecycle setting for the cluster.
     * 
     */
    public LifecycleConfigResponse lifecycleConfig() {
        return this.lifecycleConfig;
    }
    /**
     * @return Optional. The Compute Engine config settings for the cluster&#39;s master instance.
     * 
     */
    public InstanceGroupConfigResponse masterConfig() {
        return this.masterConfig;
    }
    /**
     * @return Optional. Metastore configuration.
     * 
     */
    public MetastoreConfigResponse metastoreConfig() {
        return this.metastoreConfig;
    }
    /**
     * @return Optional. The Compute Engine config settings for a cluster&#39;s secondary worker instances
     * 
     */
    public InstanceGroupConfigResponse secondaryWorkerConfig() {
        return this.secondaryWorkerConfig;
    }
    /**
     * @return Optional. Security settings for the cluster.
     * 
     */
    public SecurityConfigResponse securityConfig() {
        return this.securityConfig;
    }
    /**
     * @return Optional. The config settings for cluster software.
     * 
     */
    public SoftwareConfigResponse softwareConfig() {
        return this.softwareConfig;
    }
    /**
     * @return Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
     * 
     */
    public String tempBucket() {
        return this.tempBucket;
    }
    /**
     * @return Optional. The Compute Engine config settings for the cluster&#39;s worker instances.
     * 
     */
    public InstanceGroupConfigResponse workerConfig() {
        return this.workerConfig;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(ClusterConfigResponse defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private AutoscalingConfigResponse autoscalingConfig;
        private String configBucket;
        private DataprocMetricConfigResponse dataprocMetricConfig;
        private EncryptionConfigResponse encryptionConfig;
        private EndpointConfigResponse endpointConfig;
        private GceClusterConfigResponse gceClusterConfig;
        private GkeClusterConfigResponse gkeClusterConfig;
        private List<NodeInitializationActionResponse> initializationActions;
        private LifecycleConfigResponse lifecycleConfig;
        private InstanceGroupConfigResponse masterConfig;
        private MetastoreConfigResponse metastoreConfig;
        private InstanceGroupConfigResponse secondaryWorkerConfig;
        private SecurityConfigResponse securityConfig;
        private SoftwareConfigResponse softwareConfig;
        private String tempBucket;
        private InstanceGroupConfigResponse workerConfig;
        public Builder() {}
        public Builder(ClusterConfigResponse defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.autoscalingConfig = defaults.autoscalingConfig;
    	      this.configBucket = defaults.configBucket;
    	      this.dataprocMetricConfig = defaults.dataprocMetricConfig;
    	      this.encryptionConfig = defaults.encryptionConfig;
    	      this.endpointConfig = defaults.endpointConfig;
    	      this.gceClusterConfig = defaults.gceClusterConfig;
    	      this.gkeClusterConfig = defaults.gkeClusterConfig;
    	      this.initializationActions = defaults.initializationActions;
    	      this.lifecycleConfig = defaults.lifecycleConfig;
    	      this.masterConfig = defaults.masterConfig;
    	      this.metastoreConfig = defaults.metastoreConfig;
    	      this.secondaryWorkerConfig = defaults.secondaryWorkerConfig;
    	      this.securityConfig = defaults.securityConfig;
    	      this.softwareConfig = defaults.softwareConfig;
    	      this.tempBucket = defaults.tempBucket;
    	      this.workerConfig = defaults.workerConfig;
        }

        @CustomType.Setter
        public Builder autoscalingConfig(AutoscalingConfigResponse autoscalingConfig) {
            this.autoscalingConfig = Objects.requireNonNull(autoscalingConfig);
            return this;
        }
        @CustomType.Setter
        public Builder configBucket(String configBucket) {
            this.configBucket = Objects.requireNonNull(configBucket);
            return this;
        }
        @CustomType.Setter
        public Builder dataprocMetricConfig(DataprocMetricConfigResponse dataprocMetricConfig) {
            this.dataprocMetricConfig = Objects.requireNonNull(dataprocMetricConfig);
            return this;
        }
        @CustomType.Setter
        public Builder encryptionConfig(EncryptionConfigResponse encryptionConfig) {
            this.encryptionConfig = Objects.requireNonNull(encryptionConfig);
            return this;
        }
        @CustomType.Setter
        public Builder endpointConfig(EndpointConfigResponse endpointConfig) {
            this.endpointConfig = Objects.requireNonNull(endpointConfig);
            return this;
        }
        @CustomType.Setter
        public Builder gceClusterConfig(GceClusterConfigResponse gceClusterConfig) {
            this.gceClusterConfig = Objects.requireNonNull(gceClusterConfig);
            return this;
        }
        @CustomType.Setter
        public Builder gkeClusterConfig(GkeClusterConfigResponse gkeClusterConfig) {
            this.gkeClusterConfig = Objects.requireNonNull(gkeClusterConfig);
            return this;
        }
        @CustomType.Setter
        public Builder initializationActions(List<NodeInitializationActionResponse> initializationActions) {
            this.initializationActions = Objects.requireNonNull(initializationActions);
            return this;
        }
        public Builder initializationActions(NodeInitializationActionResponse... initializationActions) {
            return initializationActions(List.of(initializationActions));
        }
        @CustomType.Setter
        public Builder lifecycleConfig(LifecycleConfigResponse lifecycleConfig) {
            this.lifecycleConfig = Objects.requireNonNull(lifecycleConfig);
            return this;
        }
        @CustomType.Setter
        public Builder masterConfig(InstanceGroupConfigResponse masterConfig) {
            this.masterConfig = Objects.requireNonNull(masterConfig);
            return this;
        }
        @CustomType.Setter
        public Builder metastoreConfig(MetastoreConfigResponse metastoreConfig) {
            this.metastoreConfig = Objects.requireNonNull(metastoreConfig);
            return this;
        }
        @CustomType.Setter
        public Builder secondaryWorkerConfig(InstanceGroupConfigResponse secondaryWorkerConfig) {
            this.secondaryWorkerConfig = Objects.requireNonNull(secondaryWorkerConfig);
            return this;
        }
        @CustomType.Setter
        public Builder securityConfig(SecurityConfigResponse securityConfig) {
            this.securityConfig = Objects.requireNonNull(securityConfig);
            return this;
        }
        @CustomType.Setter
        public Builder softwareConfig(SoftwareConfigResponse softwareConfig) {
            this.softwareConfig = Objects.requireNonNull(softwareConfig);
            return this;
        }
        @CustomType.Setter
        public Builder tempBucket(String tempBucket) {
            this.tempBucket = Objects.requireNonNull(tempBucket);
            return this;
        }
        @CustomType.Setter
        public Builder workerConfig(InstanceGroupConfigResponse workerConfig) {
            this.workerConfig = Objects.requireNonNull(workerConfig);
            return this;
        }
        public ClusterConfigResponse build() {
            final var o = new ClusterConfigResponse();
            o.autoscalingConfig = autoscalingConfig;
            o.configBucket = configBucket;
            o.dataprocMetricConfig = dataprocMetricConfig;
            o.encryptionConfig = encryptionConfig;
            o.endpointConfig = endpointConfig;
            o.gceClusterConfig = gceClusterConfig;
            o.gkeClusterConfig = gkeClusterConfig;
            o.initializationActions = initializationActions;
            o.lifecycleConfig = lifecycleConfig;
            o.masterConfig = masterConfig;
            o.metastoreConfig = metastoreConfig;
            o.secondaryWorkerConfig = secondaryWorkerConfig;
            o.securityConfig = securityConfig;
            o.softwareConfig = softwareConfig;
            o.tempBucket = tempBucket;
            o.workerConfig = workerConfig;
            return o;
        }
    }
}
